
# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import warnings
warnings.filterwarnings('ignore')
# Set style for better visualizations

print("="*80)
print("HOUSE PRICE PREDICTION - REGRESSION ANALYSIS PROJECT")
print("="*80)
# ==============================================================================
# STEP 1: DATA LOADING AND EXPLORATION
# ==============================================================================
print("\n[STEP 1] Loading and Exploring Data...")
print("-"*80)
# Load the dataset
df = pd.read_csv('house_price_prediction.csv')

print(f"\nDataset Shape: {df.shape}")

print("\nFirst 5 Records:")
print(df.head(5))

print("\nDataset Information:")
print(df.info())

print("\nStatistical Summary:")
print(df.describe())

print("\nMissing Values:")
print(df.isnull().sum())

# Handle missing values by dropping rows with NaN
print(f"\nOriginal dataset size: {df.shape[0]} rows")
df = df.dropna()
print(f"After removing missing values: {df.shape[0]} rows")

# ==============================================================================
# STEP 2: DATA VISUALIZATION (INDIVIDUAL GRAPHS)
# ==============================================================================

print("\n[STEP 2] Creating Visualizations (Har graph alag window mein)...")
print("-"*80)
print("NOTE: Har graph ko dekh kar CLOSE karo, phir agla graph dikhega!")
print("-"*80)

# GRAPH 1: Distribution of House Prices
print("\nüìä Graph 1: House Price Distribution")
plt.figure(figsize=(10, 6))
plt.hist(df['price'], bins=50, edgecolor='black', alpha=0.7, color='lightpink')
plt.xlabel('House Price ($)', fontweight='bold', fontsize=12)
plt.ylabel('Frequency', fontweight='bold', fontsize=12)
plt.title('Distribution of House Prices', fontweight='bold', fontsize=14)
plt.ticklabel_format(style='plain', axis='x')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('./01_price_distribution.png', dpi=300, bbox_inches='tight')
print("‚úì Saved: 01_price_distribution.png")
plt.show()  # Yaha rukk jayega, close karo toh aage badhega
input("Press ENTER to continue to next graph...")

# GRAPH 2: Correlation Heatmap
print("\nüìä Graph 2: Correlation Heatmap")
plt.figure(figsize=(10, 8))
numeric_cols = ['avg_income', 'avg_area_house_age', 'avg_area_num_rooms', 
                'avg_bedrooms', 'avg_population', 'price']
correlation_matrix = df[numeric_cols].corr()
sns.heatmap(correlation_matrix, annot=True, fmt='.3f', cmap='coolwarm', 
            square=True, cbar_kws={'shrink': 0.8}, linewidths=2, linecolor='white')
plt.title('Feature Correlation Heatmap', fontweight='bold', fontsize=14)
plt.tight_layout()
plt.savefig('./02_correlation_heatmap.png', dpi=300, bbox_inches='tight')
print("‚úì Saved: 02_correlation_heatmap.png")
plt.show()
input("Press ENTER to continue to next graph...")

# GRAPH 3: Income vs Price
print("\nüìä Graph 3: Income vs Price")
plt.figure(figsize=(10, 6))
plt.scatter(df['avg_income'], df['price'], alpha=0.5, s=30, color='blue')
z = np.polyfit(df['avg_income'], df['price'], 1)
p = np.poly1d(z)
plt.plot(df['avg_income'], p(df['avg_income']), "r--", linewidth=2, label='Trend Line')
corr = df['avg_income'].corr(df['price'])
plt.xlabel('Average Income ($)', fontweight='bold', fontsize=12)
plt.ylabel('House Price ($)', fontweight='bold', fontsize=12)
plt.title(f'Income vs Price (Correlation: {corr:.3f})', fontweight='bold', fontsize=14)
plt.ticklabel_format(style='plain')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('./03_income_vs_price.png', dpi=300, bbox_inches='tight')
print("‚úì Saved: 03_income_vs_price.png")
plt.show()
input("Press ENTER to continue to next graph...")

# GRAPH 4: House Age vs Price
print("\nüìä Graph 4: House Age vs Price")
plt.figure(figsize=(10, 6))
plt.scatter(df['avg_area_house_age'], df['price'], alpha=0.5, s=30, color='green')
z = np.polyfit(df['avg_area_house_age'], df['price'], 1)
p = np.poly1d(z)
plt.plot(df['avg_area_house_age'], p(df['avg_area_house_age']), "r--", linewidth=2, label='Trend Line')
corr = df['avg_area_house_age'].corr(df['price'])
plt.xlabel('House Age (years)', fontweight='bold', fontsize=12)
plt.ylabel('House Price ($)', fontweight='bold', fontsize=12)
plt.title(f'House Age vs Price (Correlation: {corr:.3f})', fontweight='bold', fontsize=14)
plt.ticklabel_format(style='plain')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('./04_age_vs_price.png', dpi=300, bbox_inches='tight')
print("‚úì Saved: 04_age_vs_price.png")
plt.show()
input("Press ENTER to continue to next graph...")

# GRAPH 5: Rooms vs Price
print("\nüìä Graph 5: Number of Rooms vs Price")
plt.figure(figsize=(10, 6))
plt.scatter(df['avg_area_num_rooms'], df['price'], alpha=0.5, s=30, color='orange')
z = np.polyfit(df['avg_area_num_rooms'], df['price'], 1)
p = np.poly1d(z)
plt.plot(df['avg_area_num_rooms'], p(df['avg_area_num_rooms']), "r--", linewidth=2, label='Trend Line')
corr = df['avg_area_num_rooms'].corr(df['price'])
plt.xlabel('Number of Rooms', fontweight='bold', fontsize=12)
plt.ylabel('House Price ($)', fontweight='bold', fontsize=12)
plt.title(f'Rooms vs Price (Correlation: {corr:.3f})', fontweight='bold', fontsize=14)
plt.ticklabel_format(style='plain')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('./05_rooms_vs_price.png', dpi=300, bbox_inches='tight')
print("‚úì Saved: 05_rooms_vs_price.png")
plt.show()
input("Press ENTER to continue to next graph...")

# GRAPH 6: Box Plots for Outlier Detection
print("\nüìä Graph 6: Box Plots - Outlier Detection")
fig, axes = plt.subplots(2, 3, figsize=(15, 10))

features_box = ['price', 'avg_income', 'avg_area_house_age', 
                'avg_area_num_rooms', 'avg_bedrooms', 'avg_population']
titles_box = ['House Price', 'Average Income', 'House Age', 
              'Number of Rooms', 'Bedrooms', 'Population']

for idx, (feature, title) in enumerate(zip(features_box, titles_box)):
    row = idx // 3
    col = idx % 3
    df.boxplot(column=feature, ax=axes[row, col])
    axes[row, col].set_ylabel(title, fontweight='bold')
    axes[row, col].set_title(f'{title} - Outlier Detection', fontweight='bold')
    axes[row, col].tick_params(labelsize=10)

plt.tight_layout()
plt.savefig('./06_boxplots.png', dpi=300, bbox_inches='tight')
print("‚úì Saved: 06_boxplots.png")
plt.show()
input("Press ENTER to continue to modeling...")

# ==============================================================================
# STEP 3: DATA PREPARATION
# ==============================================================================

print("\n[STEP 3] Preparing Data for Modeling...")
print("-"*80)

# Select features and target
X = df[['avg_income', 'avg_area_house_age', 'avg_area_num_rooms', 
        'avg_bedrooms', 'avg_population']]
y = df['price']

# Split data into training and testing sets (80-20 split)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"Training set size: {X_train.shape[0]} samples")
print(f"Testing set size: {X_test.shape[0]} samples")
print(f"Features: {list(X.columns)}")

# ==============================================================================
# STEP 4: SIMPLE LINEAR REGRESSION
# ==============================================================================

print("\n[STEP 4] Simple Linear Regression (Using Average Income)")
print("-"*80)

# Use only one feature: Average Income (highest correlation with price)
X_train_simple = X_train[['avg_income']]
X_test_simple = X_test[['avg_income']]

# Create and train the model
simple_model = LinearRegression()
simple_model.fit(X_train_simple, y_train)

# Make predictions
y_pred_simple_train = simple_model.predict(X_train_simple)
y_pred_simple_test = simple_model.predict(X_test_simple)

# Calculate metrics
simple_train_r2 = r2_score(y_train, y_pred_simple_train)
simple_test_r2 = r2_score(y_test, y_pred_simple_test)
simple_rmse = np.sqrt(mean_squared_error(y_test, y_pred_simple_test))
simple_mae = mean_absolute_error(y_test, y_pred_simple_test)

print(f"\nModel Equation: Price = {simple_model.intercept_:.2f} + "
      f"{simple_model.coef_[0]:.2f} √ó Income")
print(f"\nTraining R¬≤ Score: {simple_train_r2:.4f}")
print(f"Testing R¬≤ Score: {simple_test_r2:.4f}")
print(f"Root Mean Squared Error (RMSE): ${simple_rmse:,.2f}")
print(f"Mean Absolute Error (MAE): ${simple_mae:,.2f}")

# GRAPH 7: Simple Linear Regression - Regression Line
print("\nüìä Graph 7: Simple Linear Regression - Regression Line")
plt.figure(figsize=(10, 6))
plt.scatter(X_test_simple, y_test, alpha=0.5, label='Actual Prices', s=30, color='blue')
plt.plot(X_test_simple, y_pred_simple_test, color='red', 
         linewidth=3, label='Regression Line')
plt.xlabel('Average Income ($)', fontweight='bold', fontsize=12)
plt.ylabel('House Price ($)', fontweight='bold', fontsize=12)
plt.title(f'Simple Linear Regression: Income vs Price\nR¬≤ = {simple_test_r2:.4f}', 
          fontweight='bold', fontsize=14)
plt.legend(fontsize=11)
plt.ticklabel_format(style='plain')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('./07_simple_regression_line.png', dpi=300, bbox_inches='tight')
print("‚úì Saved: 07_simple_regression_line.png")
plt.show()
input("Press ENTER to continue...")

# GRAPH 8: Simple Linear Regression - Residual Plot
print("\nüìä Graph 8: Simple Linear Regression - Residual Plot")
residuals_simple = y_test - y_pred_simple_test
plt.figure(figsize=(10, 6))
plt.scatter(y_pred_simple_test, residuals_simple, alpha=0.5, s=30, color='green')
plt.axhline(y=0, color='red', linestyle='--', linewidth=2, label='Zero Error Line')
plt.xlabel('Predicted Price ($)', fontweight='bold', fontsize=12)
plt.ylabel('Residuals ($)', fontweight='bold', fontsize=12)
plt.title('Residual Plot - Simple Linear Regression', fontweight='bold', fontsize=14)
plt.ticklabel_format(style='plain')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('./08_simple_residuals.png', dpi=300, bbox_inches='tight')
print("‚úì Saved: 08_simple_residuals.png")
plt.show()
input("Press ENTER to continue...")

# ==============================================================================
# STEP 5: MULTIPLE LINEAR REGRESSION
# ==============================================================================

print("\n[STEP 5] Multiple Linear Regression (Using All Features)")
print("-"*80)

# Create and train the model
multiple_model = LinearRegression()
multiple_model.fit(X_train, y_train)

# Make predictions
y_pred_multiple_train = multiple_model.predict(X_train)
y_pred_multiple_test = multiple_model.predict(X_test)

# Calculate metrics
multiple_train_r2 = r2_score(y_train, y_pred_multiple_train)
multiple_test_r2 = r2_score(y_test, y_pred_multiple_test)
multiple_rmse = np.sqrt(mean_squared_error(y_test, y_pred_multiple_test))
multiple_mae = mean_absolute_error(y_test, y_pred_multiple_test)

print(f"\nModel Equation:")
print(f"Price = {multiple_model.intercept_:.2f}")
for feature, coef in zip(X.columns, multiple_model.coef_):
    print(f"        + {coef:.2f} √ó {feature}")

print(f"\nTraining R¬≤ Score: {multiple_train_r2:.4f}")
print(f"Testing R¬≤ Score: {multiple_test_r2:.4f}")
print(f"Root Mean Squared Error (RMSE): ${multiple_rmse:,.2f}")
print(f"Mean Absolute Error (MAE): ${multiple_mae:,.2f}")

# Feature Importance Analysis
feature_importance = pd.DataFrame({
    'Feature': X.columns,
    'Coefficient': multiple_model.coef_,
    'Abs_Coefficient': np.abs(multiple_model.coef_)
}).sort_values('Abs_Coefficient', ascending=False)

print("\nFeature Importance (by coefficient magnitude):")
print(feature_importance)

# GRAPH 9: Multiple Regression - Actual vs Predicted
print("\nüìä Graph 9: Multiple Regression - Actual vs Predicted")
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred_multiple_test, alpha=0.5, s=30, color='blue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
         'r--', lw=3, label='Perfect Prediction')
plt.xlabel('Actual Price ($)', fontweight='bold', fontsize=12)
plt.ylabel('Predicted Price ($)', fontweight='bold', fontsize=12)
plt.title(f'Actual vs Predicted Prices\nR¬≤ = {multiple_test_r2:.4f}', 
          fontweight='bold', fontsize=14)
plt.legend(fontsize=11)
plt.ticklabel_format(style='plain')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('./09_multiple_actual_vs_predicted.png', dpi=300, bbox_inches='tight')
print("‚úì Saved: 09_multiple_actual_vs_predicted.png")
plt.show()
input("Press ENTER to continue...")

# GRAPH 10: Multiple Regression - Residual Plot
print("\nüìä Graph 10: Multiple Regression - Residual Plot")
residuals_multiple = y_test - y_pred_multiple_test
plt.figure(figsize=(10, 6))
plt.scatter(y_pred_multiple_test, residuals_multiple, alpha=0.5, s=30, color='green')
plt.axhline(y=0, color='red', linestyle='--', linewidth=2, label='Zero Error Line')
plt.xlabel('Predicted Price ($)', fontweight='bold', fontsize=12)
plt.ylabel('Residuals ($)', fontweight='bold', fontsize=12)
plt.title('Residual Plot - Multiple Linear Regression', fontweight='bold', fontsize=14)
plt.ticklabel_format(style='plain')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('./10_multiple_residuals.png', dpi=300, bbox_inches='tight')
print("‚úì Saved: 10_multiple_residuals.png")
plt.show()
input("Press ENTER to continue...")

# GRAPH 11: Feature Coefficients
print("\nüìä Graph 11: Feature Coefficients")
plt.figure(figsize=(10, 6))
colors = ['green' if x > 0 else 'red' for x in feature_importance['Coefficient']]
plt.barh(feature_importance['Feature'], feature_importance['Coefficient'], color=colors, edgecolor='black')
plt.xlabel('Coefficient Value', fontweight='bold', fontsize=12)
plt.ylabel('Feature', fontweight='bold', fontsize=12)
plt.title('Feature Coefficients - Multiple Linear Regression', fontweight='bold', fontsize=14)
plt.axvline(x=0, color='black', linestyle='-', linewidth=1)
plt.grid(True, alpha=0.3, axis='x')
plt.tight_layout()
plt.savefig('./11_feature_coefficients.png', dpi=300, bbox_inches='tight')
print("‚úì Saved: 11_feature_coefficients.png")
plt.show()
input("Press ENTER to continue...")

# ==============================================================================
# STEP 6: POLYNOMIAL REGRESSION
# ==============================================================================

print("\n[STEP 6] Polynomial Regression")
print("-"*80)

# Test different polynomial degrees
degrees = [2, 3, 4]
poly_results = {}

for degree in degrees:
    print(f"\n--- Degree {degree} Polynomial ---")
    
    # Create polynomial features
    poly_features = PolynomialFeatures(degree=degree, include_bias=False)
    X_train_poly = poly_features.fit_transform(X_train)
    X_test_poly = poly_features.transform(X_test)
    
    # Train model
    poly_model = LinearRegression()
    poly_model.fit(X_train_poly, y_train)
    
    # Make predictions
    y_pred_poly_train = poly_model.predict(X_train_poly)
    y_pred_poly_test = poly_model.predict(X_test_poly)
    
    # Calculate metrics
    train_r2 = r2_score(y_train, y_pred_poly_train)
    test_r2 = r2_score(y_test, y_pred_poly_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred_poly_test))
    mae = mean_absolute_error(y_test, y_pred_poly_test)
    
    poly_results[degree] = {
        'model': poly_model,
        'poly_features': poly_features,
        'train_r2': train_r2,
        'test_r2': test_r2,
        'rmse': rmse,
        'mae': mae,
        'predictions': y_pred_poly_test
    }
    
    print(f"Training R¬≤ Score: {train_r2:.4f}")
    print(f"Testing R¬≤ Score: {test_r2:.4f}")
    print(f"RMSE: ${rmse:,.2f}")
    print(f"MAE: ${mae:,.2f}")
    print(f"Number of features: {X_train_poly.shape[1]}")

# GRAPH 12-14: Polynomial Regression Results (Each Degree Separate)
for degree in degrees:
    print(f"\nüìä Graph {11+degree}: Polynomial Regression - Degree {degree}")
    plt.figure(figsize=(10, 6))
    y_pred = poly_results[degree]['predictions']
    plt.scatter(y_test, y_pred, alpha=0.5, s=30, color='blue')
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
             'r--', lw=3, label='Perfect Prediction')
    plt.xlabel('Actual Price ($)', fontweight='bold', fontsize=12)
    plt.ylabel('Predicted Price ($)', fontweight='bold', fontsize=12)
    plt.title(f'Polynomial Regression (Degree {degree})\nR¬≤ = {poly_results[degree]["test_r2"]:.4f}',
              fontweight='bold', fontsize=14)
    plt.ticklabel_format(style='plain')
    plt.legend(fontsize=11)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(f'./{11+degree}_polynomial_degree_{degree}.png', dpi=300, bbox_inches='tight')
    print(f"‚úì Saved: {11+degree}_polynomial_degree_{degree}.png")
    plt.show()
    input("Press ENTER to continue...")

# ==============================================================================
# STEP 7: MODEL COMPARISON
# ==============================================================================

print("\n[STEP 7] Final Model Comparison")
print("="*80)

# Create comparison dataframe
comparison_df = pd.DataFrame({
    'Model': ['Simple Linear', 'Multiple Linear', 'Polynomial (Deg 2)', 
              'Polynomial (Deg 3)', 'Polynomial (Deg 4)'],
    'Training R¬≤': [simple_train_r2, multiple_train_r2] + 
                   [poly_results[d]['train_r2'] for d in degrees],
    'Testing R¬≤': [simple_test_r2, multiple_test_r2] + 
                  [poly_results[d]['test_r2'] for d in degrees],
    'RMSE': [simple_rmse, multiple_rmse] + 
            [poly_results[d]['rmse'] for d in degrees],
    'MAE': [simple_mae, multiple_mae] + 
           [poly_results[d]['mae'] for d in degrees]
})

print("\n" + "="*80)
print("COMPREHENSIVE MODEL COMPARISON")
print("="*80)
print(comparison_df.to_string(index=False))

# Find best model
best_model_idx = comparison_df['Testing R¬≤'].idxmax()
best_model_name = comparison_df.loc[best_model_idx, 'Model']
best_r2 = comparison_df.loc[best_model_idx, 'Testing R¬≤']

print("\n" + "="*80)
print(f"üèÜ BEST MODEL: {best_model_name}")
print(f"   Testing R¬≤ Score: {best_r2:.4f}")
print(f"   This model explains {best_r2*100:.2f}% of the variance in house prices!")
print("="*80)

# GRAPH 15: R¬≤ Score Comparison
print("\nüìä Graph 15: R¬≤ Score Comparison")
plt.figure(figsize=(12, 6))
colors_r2 = ['gold' if i == best_model_idx else 'skyblue' for i in range(len(comparison_df))]
plt.barh(comparison_df['Model'], comparison_df['Testing R¬≤'], 
         color=colors_r2, edgecolor='black', linewidth=2)
plt.xlabel('R¬≤ Score', fontweight='bold', fontsize=12)
plt.title('Testing R¬≤ Score Comparison (Higher is Better)', fontweight='bold', fontsize=14)
plt.xlim([0, 1])
plt.axvline(x=best_r2, color='red', linestyle='--', linewidth=2,
            label=f'Best: {best_r2:.4f}')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3, axis='x')
plt.tight_layout()
plt.savefig('./15_r2_comparison.png', dpi=300, bbox_inches='tight')
print("‚úì Saved: 15_r2_comparison.png")
plt.show()
input("Press ENTER to continue...")

# GRAPH 16: RMSE Comparison
print("\nüìä Graph 16: RMSE Comparison")
plt.figure(figsize=(12, 6))
colors_rmse = ['gold' if comparison_df.loc[i, 'RMSE'] == comparison_df['RMSE'].min() 
               else 'lightcoral' for i in range(len(comparison_df))]
plt.barh(comparison_df['Model'], comparison_df['RMSE'], 
         color=colors_rmse, edgecolor='black', linewidth=2)
plt.xlabel('RMSE ($)', fontweight='bold', fontsize=12)
plt.title('Root Mean Squared Error Comparison (Lower is Better)', fontweight='bold', fontsize=14)
plt.ticklabel_format(style='plain', axis='x')
plt.grid(True, alpha=0.3, axis='x')
plt.tight_layout()
plt.savefig('./16_rmse_comparison.png', dpi=300, bbox_inches='tight')
print("‚úì Saved: 16_rmse_comparison.png")
plt.show()
input("Press ENTER to continue...")

# GRAPH 17: Training vs Testing R¬≤
print("\nüìä Graph 17: Training vs Testing R¬≤ Comparison")
plt.figure(figsize=(12, 6))
x_pos = np.arange(len(comparison_df))
width = 0.35
plt.bar(x_pos - width/2, comparison_df['Training R¬≤'], width, 
        label='Training', color='lightgreen', edgecolor='black', linewidth=2)
plt.bar(x_pos + width/2, comparison_df['Testing R¬≤'], width, 
        label='Testing', color='lightblue', edgecolor='black', linewidth=2)
plt.xlabel('Model', fontweight='bold', fontsize=12)
plt.ylabel('R¬≤ Score', fontweight='bold', fontsize=12)
plt.title('Training vs Testing R¬≤ Score (Close = Good Generalization)', 
          fontweight='bold', fontsize=14)
plt.xticks(x_pos, comparison_df['Model'], rotation=45, ha='right')
plt.legend(fontsize=11)
plt.ylim([0, 1])
plt.grid(True, alpha=0.3, axis='y')
plt.tight_layout()
plt.savefig('./17_train_vs_test.png', dpi=300, bbox_inches='tight')
print("‚úì Saved: 17_train_vs_test.png")
plt.show()
input("Press ENTER to continue...")

# ==============================================================================
# STEP 8: PRACTICAL PREDICTIONS
# ==============================================================================

print("\n[STEP 8] Making Practical Predictions")
print("="*80)

# Example prediction scenarios
example_houses = pd.DataFrame({
    'avg_income': [75000, 85000, 60000],
    'avg_area_house_age': [5, 7, 4],
    'avg_area_num_rooms': [7, 8, 6],
    'avg_bedrooms': [3, 4, 3],
    'avg_population': [30000, 35000, 25000]
})

print("\nExample Houses for Prediction:")
print(example_houses)

# Make predictions with the best model (Multiple Linear)
predictions = multiple_model.predict(example_houses)

print("\n" + "-"*80)
print("PREDICTED HOUSE PRICES:")
print("-"*80)
for i, pred in enumerate(predictions, 1):
    print(f"House {i}: ${pred:,.2f}")

# GRAPH 18: Prediction Examples
print("\nüìä Graph 18: Prediction Examples")
plt.figure(figsize=(12, 6))
plt.bar(range(1, len(predictions)+1), predictions, 
        color='skyblue', edgecolor='black', linewidth=2)
plt.xlabel('House Number', fontweight='bold', fontsize=12)
plt.ylabel('Predicted Price ($)', fontweight='bold', fontsize=12)
plt.title('Predicted Prices for Example Houses', fontweight='bold', fontsize=14)
plt.ticklabel_format(style='plain', axis='y')
plt.grid(True, alpha=0.3, axis='y')
for i, pred in enumerate(predictions):
    plt.text(i+1, pred, f'${pred:,.0f}', ha='center', va='bottom', 
             fontweight='bold', fontsize=10)
plt.tight_layout()
plt.savefig('./18_predictions.png', dpi=300, bbox_inches='tight')
print("‚úì Saved: 18_predictions.png")
plt.show()

# ==============================================================================
# CONCLUSION
# ==============================================================================

print("\n" + "="*80)
print("PROJECT SUMMARY")
print("="*80)
print(f"""
‚úì Data Exploration: Analyzed {df.shape[0]:,} house records with {X.shape[1]} features
‚úì Simple Linear Regression: R¬≤ = {simple_test_r2:.4f}
‚úì Multiple Linear Regression: R¬≤ = {multiple_test_r2:.4f} (BEST!)
‚úì Polynomial Regression: Tested degrees 2, 3, and 4
‚úì Total Graphs Created: 18 individual visualization files
‚úì Best Model: {best_model_name} with {best_r2*100:.2f}% accuracy

Key Findings:
1. Multiple features provide much better predictions (92% vs 44%)
2. House age and room count are most influential features
3. Polynomial regression didn't significantly improve results
4. Model shows good generalization (no overfitting)

Files Saved:
- 18 PNG files with detailed visualizations
- All graphs shown individually for better understanding
""")
print("="*80)
print("\n‚úÖ PROJECT COMPLETED SUCCESSFULLY!")
print("\n="*80)



















# """
# ==============================================================================
# MINI PROJECT: House Price Prediction Using Regression Analysis
# INDIVIDUAL GRAPH DISPLAY VERSION
# ==============================================================================

# Dataset: House Price Prediction Dataset
# Features: Average Income, House Age, Number of Rooms, Bedrooms, Population

# Har graph alag-alag window mein dikhega!

# Author: Data Science Student
# Date: December 2025
# ==============================================================================
# """

# # Import necessary libraries
# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# from sklearn.model_selection import train_test_split
# from sklearn.linear_model import LinearRegression
# from sklearn.preprocessing import PolynomialFeatures
# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
# import warnings
# warnings.filterwarnings('ignore')

# # Set style for better visualizations
# plt.style.use('seaborn-v0_8-darkgrid')
# sns.set_palette("husl")

# print("="*80)
# print("HOUSE PRICE PREDICTION - REGRESSION ANALYSIS PROJECT")
# print("="*80)

# # ==============================================================================
# # STEP 1: DATA LOADING AND EXPLORATION
# # ==============================================================================

# print("\n[STEP 1] Loading and Exploring Data...")
# print("-"*80)

# # Load the dataset
# df = pd.read_csv('house_price_prediction.csv')

# print(f"\nDataset Shape: {df.shape}")
# print(f"Number of Records: {df.shape[0]}")
# print(f"Number of Features: {df.shape[1]}")

# print("\nFirst 5 Records:")
# print(df.head())

# print("\nDataset Information:")
# print(df.info())

# print("\nStatistical Summary:")
# print(df.describe())

# print("\nMissing Values:")
# print(df.isnull().sum())

# # Handle missing values by dropping rows with NaN
# print(f"\nOriginal dataset size: {df.shape[0]} rows")
# df = df.dropna()
# print(f"After removing missing values: {df.shape[0]} rows")

# # ==============================================================================
# # STEP 2: DATA VISUALIZATION (INDIVIDUAL GRAPHS)
# # ==============================================================================

# print("\n[STEP 2] Creating Visualizations (Har graph alag window mein)...")
# print("-"*80)
# print("NOTE: Har graph ko dekh kar CLOSE karo, phir agla graph dikhega!")
# print("-"*80)

# # GRAPH 1: Distribution of House Prices
# print("\nüìä Graph 1: House Price Distribution")
# plt.figure(figsize=(10, 6))
# plt.hist(df['price'], bins=50, edgecolor='black', alpha=0.7, color='skyblue')
# plt.xlabel('House Price ($)', fontweight='bold', fontsize=12)
# plt.ylabel('Frequency', fontweight='bold', fontsize=12)
# plt.title('Distribution of House Prices', fontweight='bold', fontsize=14)
# plt.ticklabel_format(style='plain', axis='x')
# plt.grid(True, alpha=0.3)
# plt.tight_layout()
# plt.savefig('./01_price_distribution.png', dpi=300, bbox_inches='tight')
# print("‚úì Saved: 01_price_distribution.png")
# plt.show()  # Yaha rukk jayega, close karo toh aage badhega
# input("Press ENTER to continue to next graph...")

# # GRAPH 2: Correlation Heatmap
# print("\nüìä Graph 2: Correlation Heatmap")
# plt.figure(figsize=(10, 8))
# numeric_cols = ['avg_income', 'avg_area_house_age', 'avg_area_num_rooms', 
#                 'avg_bedrooms', 'avg_population', 'price']
# correlation_matrix = df[numeric_cols].corr()
# sns.heatmap(correlation_matrix, annot=True, fmt='.3f', cmap='coolwarm', 
#             square=True, cbar_kws={'shrink': 0.8}, linewidths=2, linecolor='white')
# plt.title('Feature Correlation Heatmap', fontweight='bold', fontsize=14)
# plt.tight_layout()
# plt.savefig('./02_correlation_heatmap.png', dpi=300, bbox_inches='tight')
# print("‚úì Saved: 02_correlation_heatmap.png")
# plt.show()
# input("Press ENTER to continue to next graph...")

# # GRAPH 3: Income vs Price
# print("\nüìä Graph 3: Income vs Price")
# plt.figure(figsize=(10, 6))
# plt.scatter(df['avg_income'], df['price'], alpha=0.5, s=30, color='blue')
# z = np.polyfit(df['avg_income'], df['price'], 1)
# p = np.poly1d(z)
# plt.plot(df['avg_income'], p(df['avg_income']), "r--", linewidth=2, label='Trend Line')
# corr = df['avg_income'].corr(df['price'])
# plt.xlabel('Average Income ($)', fontweight='bold', fontsize=12)
# plt.ylabel('House Price ($)', fontweight='bold', fontsize=12)
# plt.title(f'Income vs Price (Correlation: {corr:.3f})', fontweight='bold', fontsize=14)
# plt.ticklabel_format(style='plain')
# plt.legend()
# plt.grid(True, alpha=0.3)
# plt.tight_layout()
# plt.savefig('./03_income_vs_price.png', dpi=300, bbox_inches='tight')
# print("‚úì Saved: 03_income_vs_price.png")
# plt.show()
# input("Press ENTER to continue to next graph...")

# # GRAPH 4: House Age vs Price
# print("\nüìä Graph 4: House Age vs Price")
# plt.figure(figsize=(10, 6))
# plt.scatter(df['avg_area_house_age'], df['price'], alpha=0.5, s=30, color='green')
# z = np.polyfit(df['avg_area_house_age'], df['price'], 1)
# p = np.poly1d(z)
# plt.plot(df['avg_area_house_age'], p(df['avg_area_house_age']), "r--", linewidth=2, label='Trend Line')
# corr = df['avg_area_house_age'].corr(df['price'])
# plt.xlabel('House Age (years)', fontweight='bold', fontsize=12)
# plt.ylabel('House Price ($)', fontweight='bold', fontsize=12)
# plt.title(f'House Age vs Price (Correlation: {corr:.3f})', fontweight='bold', fontsize=14)
# plt.ticklabel_format(style='plain')
# plt.legend()
# plt.grid(True, alpha=0.3)
# plt.tight_layout()
# plt.savefig('./04_age_vs_price.png', dpi=300, bbox_inches='tight')
# print("‚úì Saved: 04_age_vs_price.png")
# plt.show()
# input("Press ENTER to continue to next graph...")

# # GRAPH 5: Rooms vs Price
# print("\nüìä Graph 5: Number of Rooms vs Price")
# plt.figure(figsize=(10, 6))
# plt.scatter(df['avg_area_num_rooms'], df['price'], alpha=0.5, s=30, color='orange')
# z = np.polyfit(df['avg_area_num_rooms'], df['price'], 1)
# p = np.poly1d(z)
# plt.plot(df['avg_area_num_rooms'], p(df['avg_area_num_rooms']), "r--", linewidth=2, label='Trend Line')
# corr = df['avg_area_num_rooms'].corr(df['price'])
# plt.xlabel('Number of Rooms', fontweight='bold', fontsize=12)
# plt.ylabel('House Price ($)', fontweight='bold', fontsize=12)
# plt.title(f'Rooms vs Price (Correlation: {corr:.3f})', fontweight='bold', fontsize=14)
# plt.ticklabel_format(style='plain')
# plt.legend()
# plt.grid(True, alpha=0.3)
# plt.tight_layout()
# plt.savefig('./05_rooms_vs_price.png', dpi=300, bbox_inches='tight')
# print("‚úì Saved: 05_rooms_vs_price.png")
# plt.show()
# input("Press ENTER to continue to next graph...")

# # GRAPH 6: Box Plots for Outlier Detection
# print("\nüìä Graph 6: Box Plots - Outlier Detection")
# fig, axes = plt.subplots(2, 3, figsize=(15, 10))

# features_box = ['price', 'avg_income', 'avg_area_house_age', 
#                 'avg_area_num_rooms', 'avg_bedrooms', 'avg_population']
# titles_box = ['House Price', 'Average Income', 'House Age', 
#               'Number of Rooms', 'Bedrooms', 'Population']

# for idx, (feature, title) in enumerate(zip(features_box, titles_box)):
#     row = idx // 3
#     col = idx % 3
#     df.boxplot(column=feature, ax=axes[row, col])
#     axes[row, col].set_ylabel(title, fontweight='bold')
#     axes[row, col].set_title(f'{title} - Outlier Detection', fontweight='bold')
#     axes[row, col].tick_params(labelsize=10)

# plt.tight_layout()
# plt.savefig('./06_boxplots.png', dpi=300, bbox_inches='tight')
# print("‚úì Saved: 06_boxplots.png")
# plt.show()
# input("Press ENTER to continue to modeling...")

# # ==============================================================================
# # STEP 3: DATA PREPARATION
# # ==============================================================================

# print("\n[STEP 3] Preparing Data for Modeling...")
# print("-"*80)

# # Select features and target
# X = df[['avg_income', 'avg_area_house_age', 'avg_area_num_rooms', 
#         'avg_bedrooms', 'avg_population']]
# y = df['price']

# # Split data into training and testing sets (80-20 split)
# X_train, X_test, y_train, y_test = train_test_split(
#     X, y, test_size=0.2, random_state=42
# )

# print(f"Training set size: {X_train.shape[0]} samples")
# print(f"Testing set size: {X_test.shape[0]} samples")
# print(f"Features: {list(X.columns)}")

# # ==============================================================================
# # STEP 4: SIMPLE LINEAR REGRESSION
# # ==============================================================================

# print("\n[STEP 4] Simple Linear Regression (Using Average Income)")
# print("-"*80)

# # Use only one feature: Average Income (highest correlation with price)
# X_train_simple = X_train[['avg_income']]
# X_test_simple = X_test[['avg_income']]

# # Create and train the model
# simple_model = LinearRegression()
# simple_model.fit(X_train_simple, y_train)

# # Make predictions
# y_pred_simple_train = simple_model.predict(X_train_simple)
# y_pred_simple_test = simple_model.predict(X_test_simple)

# # Calculate metrics
# simple_train_r2 = r2_score(y_train, y_pred_simple_train)
# simple_test_r2 = r2_score(y_test, y_pred_simple_test)
# simple_rmse = np.sqrt(mean_squared_error(y_test, y_pred_simple_test))
# simple_mae = mean_absolute_error(y_test, y_pred_simple_test)

# print(f"\nModel Equation: Price = {simple_model.intercept_:.2f} + "
#       f"{simple_model.coef_[0]:.2f} √ó Income")
# print(f"\nTraining R¬≤ Score: {simple_train_r2:.4f}")
# print(f"Testing R¬≤ Score: {simple_test_r2:.4f}")
# print(f"Root Mean Squared Error (RMSE): ${simple_rmse:,.2f}")
# print(f"Mean Absolute Error (MAE): ${simple_mae:,.2f}")

# # GRAPH 7: Simple Linear Regression - Regression Line
# print("\nüìä Graph 7: Simple Linear Regression - Regression Line")
# plt.figure(figsize=(10, 6))
# plt.scatter(X_test_simple, y_test, alpha=0.5, label='Actual Prices', s=30, color='blue')
# plt.plot(X_test_simple, y_pred_simple_test, color='red', 
#          linewidth=3, label='Regression Line')
# plt.xlabel('Average Income ($)', fontweight='bold', fontsize=12)
# plt.ylabel('House Price ($)', fontweight='bold', fontsize=12)
# plt.title(f'Simple Linear Regression: Income vs Price\nR¬≤ = {simple_test_r2:.4f}', 
#           fontweight='bold', fontsize=14)
# plt.legend(fontsize=11)
# plt.ticklabel_format(style='plain')
# plt.grid(True, alpha=0.3)
# plt.tight_layout()
# plt.savefig('./07_simple_regression_line.png', dpi=300, bbox_inches='tight')
# print("‚úì Saved: 07_simple_regression_line.png")
# plt.show()
# input("Press ENTER to continue...")

# # GRAPH 8: Simple Linear Regression - Residual Plot
# print("\nüìä Graph 8: Simple Linear Regression - Residual Plot")
# residuals_simple = y_test - y_pred_simple_test
# plt.figure(figsize=(10, 6))
# plt.scatter(y_pred_simple_test, residuals_simple, alpha=0.5, s=30, color='green')
# plt.axhline(y=0, color='red', linestyle='--', linewidth=2, label='Zero Error Line')
# plt.xlabel('Predicted Price ($)', fontweight='bold', fontsize=12)
# plt.ylabel('Residuals ($)', fontweight='bold', fontsize=12)
# plt.title('Residual Plot - Simple Linear Regression', fontweight='bold', fontsize=14)
# plt.ticklabel_format(style='plain')
# plt.legend(fontsize=11)
# plt.grid(True, alpha=0.3)
# plt.tight_layout()
# plt.savefig('./08_simple_residuals.png', dpi=300, bbox_inches='tight')
# print("‚úì Saved: 08_simple_residuals.png")
# plt.show()
# input("Press ENTER to continue...")

# # ==============================================================================
# # STEP 5: MULTIPLE LINEAR REGRESSION
# # ==============================================================================

# print("\n[STEP 5] Multiple Linear Regression (Using All Features)")
# print("-"*80)

# # Create and train the model
# multiple_model = LinearRegression()
# multiple_model.fit(X_train, y_train)

# # Make predictions
# y_pred_multiple_train = multiple_model.predict(X_train)
# y_pred_multiple_test = multiple_model.predict(X_test)

# # Calculate metrics
# multiple_train_r2 = r2_score(y_train, y_pred_multiple_train)
# multiple_test_r2 = r2_score(y_test, y_pred_multiple_test)
# multiple_rmse = np.sqrt(mean_squared_error(y_test, y_pred_multiple_test))
# multiple_mae = mean_absolute_error(y_test, y_pred_multiple_test)

# print(f"\nModel Equation:")
# print(f"Price = {multiple_model.intercept_:.2f}")
# for feature, coef in zip(X.columns, multiple_model.coef_):
#     print(f"        + {coef:.2f} √ó {feature}")

# print(f"\nTraining R¬≤ Score: {multiple_train_r2:.4f}")
# print(f"Testing R¬≤ Score: {multiple_test_r2:.4f}")
# print(f"Root Mean Squared Error (RMSE): ${multiple_rmse:,.2f}")
# print(f"Mean Absolute Error (MAE): ${multiple_mae:,.2f}")

# # Feature Importance Analysis
# feature_importance = pd.DataFrame({
#     'Feature': X.columns,
#     'Coefficient': multiple_model.coef_,
#     'Abs_Coefficient': np.abs(multiple_model.coef_)
# }).sort_values('Abs_Coefficient', ascending=False)

# print("\nFeature Importance (by coefficient magnitude):")
# print(feature_importance)

# # GRAPH 9: Multiple Regression - Actual vs Predicted
# print("\nüìä Graph 9: Multiple Regression - Actual vs Predicted")
# plt.figure(figsize=(10, 6))
# plt.scatter(y_test, y_pred_multiple_test, alpha=0.5, s=30, color='blue')
# plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
#          'r--', lw=3, label='Perfect Prediction')
# plt.xlabel('Actual Price ($)', fontweight='bold', fontsize=12)
# plt.ylabel('Predicted Price ($)', fontweight='bold', fontsize=12)
# plt.title(f'Actual vs Predicted Prices\nR¬≤ = {multiple_test_r2:.4f}', 
#           fontweight='bold', fontsize=14)
# plt.legend(fontsize=11)
# plt.ticklabel_format(style='plain')
# plt.grid(True, alpha=0.3)
# plt.tight_layout()
# plt.savefig('./09_multiple_actual_vs_predicted.png', dpi=300, bbox_inches='tight')
# print("‚úì Saved: 09_multiple_actual_vs_predicted.png")
# plt.show()
# input("Press ENTER to continue...")

# # GRAPH 10: Multiple Regression - Residual Plot
# print("\nüìä Graph 10: Multiple Regression - Residual Plot")
# residuals_multiple = y_test - y_pred_multiple_test
# plt.figure(figsize=(10, 6))
# plt.scatter(y_pred_multiple_test, residuals_multiple, alpha=0.5, s=30, color='green')
# plt.axhline(y=0, color='red', linestyle='--', linewidth=2, label='Zero Error Line')
# plt.xlabel('Predicted Price ($)', fontweight='bold', fontsize=12)
# plt.ylabel('Residuals ($)', fontweight='bold', fontsize=12)
# plt.title('Residual Plot - Multiple Linear Regression', fontweight='bold', fontsize=14)
# plt.ticklabel_format(style='plain')
# plt.legend(fontsize=11)
# plt.grid(True, alpha=0.3)
# plt.tight_layout()
# plt.savefig('./10_multiple_residuals.png', dpi=300, bbox_inches='tight')
# print("‚úì Saved: 10_multiple_residuals.png")
# plt.show()
# input("Press ENTER to continue...")

# # GRAPH 11: Feature Coefficients
# print("\nüìä Graph 11: Feature Coefficients")
# plt.figure(figsize=(10, 6))
# colors = ['green' if x > 0 else 'red' for x in feature_importance['Coefficient']]
# plt.barh(feature_importance['Feature'], feature_importance['Coefficient'], color=colors, edgecolor='black')
# plt.xlabel('Coefficient Value', fontweight='bold', fontsize=12)
# plt.ylabel('Feature', fontweight='bold', fontsize=12)
# plt.title('Feature Coefficients - Multiple Linear Regression', fontweight='bold', fontsize=14)
# plt.axvline(x=0, color='black', linestyle='-', linewidth=1)
# plt.grid(True, alpha=0.3, axis='x')
# plt.tight_layout()
# plt.savefig('./11_feature_coefficients.png', dpi=300, bbox_inches='tight')
# print("‚úì Saved: 11_feature_coefficients.png")
# plt.show()
# input("Press ENTER to continue...")

# # ==============================================================================
# # STEP 6: POLYNOMIAL REGRESSION
# # ==============================================================================

# print("\n[STEP 6] Polynomial Regression")
# print("-"*80)

# # Test different polynomial degrees
# degrees = [2, 3, 4]
# poly_results = {}

# for degree in degrees:
#     print(f"\n--- Degree {degree} Polynomial ---")
    
#     # Create polynomial features
#     poly_features = PolynomialFeatures(degree=degree, include_bias=False)
#     X_train_poly = poly_features.fit_transform(X_train)
#     X_test_poly = poly_features.transform(X_test)
    
#     # Train model
#     poly_model = LinearRegression()
#     poly_model.fit(X_train_poly, y_train)
    
#     # Make predictions
#     y_pred_poly_train = poly_model.predict(X_train_poly)
#     y_pred_poly_test = poly_model.predict(X_test_poly)
    
#     # Calculate metrics
#     train_r2 = r2_score(y_train, y_pred_poly_train)
#     test_r2 = r2_score(y_test, y_pred_poly_test)
#     rmse = np.sqrt(mean_squared_error(y_test, y_pred_poly_test))
#     mae = mean_absolute_error(y_test, y_pred_poly_test)
    
#     poly_results[degree] = {
#         'model': poly_model,
#         'poly_features': poly_features,
#         'train_r2': train_r2,
#         'test_r2': test_r2,
#         'rmse': rmse,
#         'mae': mae,
#         'predictions': y_pred_poly_test
#     }
    
#     print(f"Training R¬≤ Score: {train_r2:.4f}")
#     print(f"Testing R¬≤ Score: {test_r2:.4f}")
#     print(f"RMSE: ${rmse:,.2f}")
#     print(f"MAE: ${mae:,.2f}")
#     print(f"Number of features: {X_train_poly.shape[1]}")

# # GRAPH 12-14: Polynomial Regression Results (Each Degree Separate)
# for degree in degrees:
#     print(f"\nüìä Graph {11+degree}: Polynomial Regression - Degree {degree}")
#     plt.figure(figsize=(10, 6))
#     y_pred = poly_results[degree]['predictions']
#     plt.scatter(y_test, y_pred, alpha=0.5, s=30, color='blue')
#     plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
#              'r--', lw=3, label='Perfect Prediction')
#     plt.xlabel('Actual Price ($)', fontweight='bold', fontsize=12)
#     plt.ylabel('Predicted Price ($)', fontweight='bold', fontsize=12)
#     plt.title(f'Polynomial Regression (Degree {degree})\nR¬≤ = {poly_results[degree]["test_r2"]:.4f}',
#               fontweight='bold', fontsize=14)
#     plt.ticklabel_format(style='plain')
#     plt.legend(fontsize=11)
#     plt.grid(True, alpha=0.3)
#     plt.tight_layout()
#     plt.savefig(f'./{11+degree}_polynomial_degree_{degree}.png', dpi=300, bbox_inches='tight')
#     print(f"‚úì Saved: {11+degree}_polynomial_degree_{degree}.png")
#     plt.show()
#     input("Press ENTER to continue...")

# # ==============================================================================
# # STEP 7: MODEL COMPARISON
# # ==============================================================================

# print("\n[STEP 7] Final Model Comparison")
# print("="*80)

# # Create comparison dataframe
# comparison_df = pd.DataFrame({
#     'Model': ['Simple Linear', 'Multiple Linear', 'Polynomial (Deg 2)', 
#               'Polynomial (Deg 3)', 'Polynomial (Deg 4)'],
#     'Training R¬≤': [simple_train_r2, multiple_train_r2] + 
#                    [poly_results[d]['train_r2'] for d in degrees],
#     'Testing R¬≤': [simple_test_r2, multiple_test_r2] + 
#                   [poly_results[d]['test_r2'] for d in degrees],
#     'RMSE': [simple_rmse, multiple_rmse] + 
#             [poly_results[d]['rmse'] for d in degrees],
#     'MAE': [simple_mae, multiple_mae] + 
#            [poly_results[d]['mae'] for d in degrees]
# })

# print("\n" + "="*80)
# print("COMPREHENSIVE MODEL COMPARISON")
# print("="*80)
# print(comparison_df.to_string(index=False))

# # Find best model
# best_model_idx = comparison_df['Testing R¬≤'].idxmax()
# best_model_name = comparison_df.loc[best_model_idx, 'Model']
# best_r2 = comparison_df.loc[best_model_idx, 'Testing R¬≤']

# print("\n" + "="*80)
# print(f"üèÜ BEST MODEL: {best_model_name}")
# print(f"   Testing R¬≤ Score: {best_r2:.4f}")
# print(f"   This model explains {best_r2*100:.2f}% of the variance in house prices!")
# print("="*80)

# # GRAPH 15: R¬≤ Score Comparison
# print("\nüìä Graph 15: R¬≤ Score Comparison")
# plt.figure(figsize=(12, 6))
# colors_r2 = ['gold' if i == best_model_idx else 'skyblue' for i in range(len(comparison_df))]
# plt.barh(comparison_df['Model'], comparison_df['Testing R¬≤'], 
#          color=colors_r2, edgecolor='black', linewidth=2)
# plt.xlabel('R¬≤ Score', fontweight='bold', fontsize=12)
# plt.title('Testing R¬≤ Score Comparison (Higher is Better)', fontweight='bold', fontsize=14)
# plt.xlim([0, 1])
# plt.axvline(x=best_r2, color='red', linestyle='--', linewidth=2,
#             label=f'Best: {best_r2:.4f}')
# plt.legend(fontsize=11)
# plt.grid(True, alpha=0.3, axis='x')
# plt.tight_layout()
# plt.savefig('./15_r2_comparison.png', dpi=300, bbox_inches='tight')
# print("‚úì Saved: 15_r2_comparison.png")
# plt.show()
# input("Press ENTER to continue...")

# # GRAPH 16: RMSE Comparison
# print("\nüìä Graph 16: RMSE Comparison")
# plt.figure(figsize=(12, 6))
# colors_rmse = ['gold' if comparison_df.loc[i, 'RMSE'] == comparison_df['RMSE'].min() 
#                else 'lightcoral' for i in range(len(comparison_df))]
# plt.barh(comparison_df['Model'], comparison_df['RMSE'], 
#          color=colors_rmse, edgecolor='black', linewidth=2)
# plt.xlabel('RMSE ($)', fontweight='bold', fontsize=12)
# plt.title('Root Mean Squared Error Comparison (Lower is Better)', fontweight='bold', fontsize=14)
# plt.ticklabel_format(style='plain', axis='x')
# plt.grid(True, alpha=0.3, axis='x')
# plt.tight_layout()
# plt.savefig('./16_rmse_comparison.png', dpi=300, bbox_inches='tight')
# print("‚úì Saved: 16_rmse_comparison.png")
# plt.show()
# input("Press ENTER to continue...")

# # GRAPH 17: Training vs Testing R¬≤
# print("\nüìä Graph 17: Training vs Testing R¬≤ Comparison")
# plt.figure(figsize=(12, 6))
# x_pos = np.arange(len(comparison_df))
# width = 0.35
# plt.bar(x_pos - width/2, comparison_df['Training R¬≤'], width, 
#         label='Training', color='lightgreen', edgecolor='black', linewidth=2)
# plt.bar(x_pos + width/2, comparison_df['Testing R¬≤'], width, 
#         label='Testing', color='lightblue', edgecolor='black', linewidth=2)
# plt.xlabel('Model', fontweight='bold', fontsize=12)
# plt.ylabel('R¬≤ Score', fontweight='bold', fontsize=12)
# plt.title('Training vs Testing R¬≤ Score (Close = Good Generalization)', 
#           fontweight='bold', fontsize=14)
# plt.xticks(x_pos, comparison_df['Model'], rotation=45, ha='right')
# plt.legend(fontsize=11)
# plt.ylim([0, 1])
# plt.grid(True, alpha=0.3, axis='y')
# plt.tight_layout()
# plt.savefig('./17_train_vs_test.png', dpi=300, bbox_inches='tight')
# print("‚úì Saved: 17_train_vs_test.png")
# plt.show()
# input("Press ENTER to continue...")

# # ==============================================================================
# # STEP 8: PRACTICAL PREDICTIONS
# # ==============================================================================

# print("\n[STEP 8] Making Practical Predictions")
# print("="*80)

# # Example prediction scenarios
# example_houses = pd.DataFrame({
#     'avg_income': [75000, 85000, 60000],
#     'avg_area_house_age': [5, 7, 4],
#     'avg_area_num_rooms': [7, 8, 6],
#     'avg_bedrooms': [3, 4, 3],
#     'avg_population': [30000, 35000, 25000]
# })

# print("\nExample Houses for Prediction:")
# print(example_houses)

# # Make predictions with the best model (Multiple Linear)
# predictions = multiple_model.predict(example_houses)

# print("\n" + "-"*80)
# print("PREDICTED HOUSE PRICES:")
# print("-"*80)
# for i, pred in enumerate(predictions, 1):
#     print(f"House {i}: ${pred:,.2f}")

# # GRAPH 18: Prediction Examples
# print("\nüìä Graph 18: Prediction Examples")
# plt.figure(figsize=(12, 6))
# plt.bar(range(1, len(predictions)+1), predictions, 
#         color='skyblue', edgecolor='black', linewidth=2)
# plt.xlabel('House Number', fontweight='bold', fontsize=12)
# plt.ylabel('Predicted Price ($)', fontweight='bold', fontsize=12)
# plt.title('Predicted Prices for Example Houses', fontweight='bold', fontsize=14)
# plt.ticklabel_format(style='plain', axis='y')
# plt.grid(True, alpha=0.3, axis='y')
# for i, pred in enumerate(predictions):
#     plt.text(i+1, pred, f'${pred:,.0f}', ha='center', va='bottom', 
#              fontweight='bold', fontsize=10)
# plt.tight_layout()
# plt.savefig('./18_predictions.png', dpi=300, bbox_inches='tight')
# print("‚úì Saved: 18_predictions.png")
# plt.show()

# # ==============================================================================
# # CONCLUSION
# # ==============================================================================

# print("\n" + "="*80)
# print("PROJECT SUMMARY")
# print("="*80)
# print(f"""
# ‚úì Data Exploration: Analyzed {df.shape[0]:,} house records with {X.shape[1]} features
# ‚úì Simple Linear Regression: R¬≤ = {simple_test_r2:.4f}
# ‚úì Multiple Linear Regression: R¬≤ = {multiple_test_r2:.4f} (BEST!)
# ‚úì Polynomial Regression: Tested degrees 2, 3, and 4
# ‚úì Total Graphs Created: 18 individual visualization files
# ‚úì Best Model: {best_model_name} with {best_r2*100:.2f}% accuracy

# Key Findings:
# 1. Multiple features provide much better predictions (92% vs 44%)
# 2. House age and room count are most influential features
# 3. Polynomial regression didn't significantly improve results
# 4. Model shows good generalization (no overfitting)

# Files Saved:
# - 18 PNG files with detailed visualizations
# - All graphs shown individually for better understanding
# """)
# print("="*80)
# print("\n‚úÖ PROJECT COMPLETED SUCCESSFULLY!")

# print("="*80)
